{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining & Machine Learning\n",
    "\n",
    "## Algorithms in use:\n",
    "\n",
    "  * Random Forest\n",
    "  * Decision Tree\n",
    "  * Knn\n",
    "\n",
    "## Our purpose is to predict which passangers we'll survive based on the passenger features\n",
    "\n",
    "<img src=\"images_for_notebook/DataMining_10.png\"/>\n",
    "<img src=\"images_for_notebook/DataMining_11.png\"/>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7fa1b512-509b-f047-372e-ba6b6dd849c2"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "titanic = pd.read_csv('titanic_raw.csv')\n",
    "\n",
    "# titanic.shape\n",
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 891 examples and 12 columns (11 features\\variables and one label). Let's look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.rename(columns=str.lower) # Rename columns to lower letters\n",
    "titanic.survived = (titanic.survived=='Yes').astype('int') # Label to numeric\n",
    "titanic = titanic.drop(['ticket','name'], axis=1) # Drop some features which aren't informative\n",
    "titanic['has_cabin'] = (titanic.cabin.isna()==False).astype(int) # Create new column \"has_cabin\"\n",
    "titanic = titanic.drop(['cabin'], axis=1) # Drop the old column \"cabin\"\n",
    "titanic = pd.get_dummies(titanic) # Categorical values to 1-hot (\"one hot\" encoding is a representation of categorical variables as binary vectors)\n",
    "titanic.age = titanic.age.fillna(titanic.age.median()) # Let's use the median to fill \"age\" column\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#FF0000\">Notice !</h1>\n",
    "<p style=\"color:#FF0000\">That this time we kept 'passengerid' column</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert all data to float because some modules warn against other types\n",
    "titanic = titanic.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values!\n",
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all values are indeed numeric (float)\n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "<img src=\"images_for_notebook/SupervisedLearning_10.png\"/>\n",
    "<img src=\"images_for_notebook/SupervisedLearning_11.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test split\n",
    "\n",
    "<img src=\"images_for_notebook/Train_Split_10.png\"/>\n",
    "<img src=\"images_for_notebook/Train_Split_11.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We only have 891 examples, let's use 200 for test and the rest for train and split to inputs and labels\n",
    "#### We'll use Scikit-Learn library\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p><u>Scikit-Learn</u></p>\n",
    "Scikit-Learn is the most popular library for machine learning in Python. It includes functions for read, write and manipulate data, as lots of optimized machine learning algorithms.\n",
    "\n",
    "The name derives from the combination <b>SCI</b>py tool<b>KIT</b> for machine <b>LEARN</b>ing. The library expands the capabilities of numpy, scipy, and pandas.\n",
    "\n",
    "\"sklearn\" is how you type the \"scikit-learn\" name in pythonm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 200\n",
    "train, test = train_test_split(titanic, test_size=test_size, random_state=0, shuffle=True)\n",
    "label = 'survived'\n",
    "x_train = train.drop(label, axis=1)\n",
    "y_train = train[label]\n",
    "x_test, y_test = test.drop(label, axis=1), test[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "## A tool to classify complex data\n",
    "\n",
    "<img src=\"images_for_notebook/DecisionTree_10.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_11.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_12.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_13.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_14.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_15.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_16.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_17.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_18.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_19.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Importing the algorithm\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "# define the algorithm:\n",
    "    # arg:\n",
    "        # max_depth = The maximum depth of the tree. (If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples)\n",
    "\n",
    "\n",
    "clf.fit(x_train, y_train) # running\\training the algorithm with the train data\n",
    "\n",
    "y_test_pred_DecisionTree = clf.predict(x_test) # making a prediction based on \"test\" data features\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'passengerid': x_test.passengerid, 'survived_what_actualy_happened':y_test, 'survived_predicted_by_model': y_test_pred_DecisionTree}) # saving results to DataFrame\n",
    "output.to_csv('my_DecisionTree_Prediction.csv', index=False) # saving results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the decision tree\n",
    "# Importing the necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "# this is afunction that we can always use for plotting decision trees, the function expects 3 arg as follows\n",
    "def plot_tree(tree, features, labels):\n",
    "    graph = Source(export_graphviz(tree, feature_names=features, class_names=labels, filled = True))\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "# Using the function above, with the 3 arg\n",
    "    # tree\n",
    "    # feaures\n",
    "    # labels --> we'll go over the example and it will be clear\n",
    "plot_tree(clf, x_train.columns, ['Died', 'Survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#FF0000\">Notice !</h3>\n",
    "If after runnig the plot for the model you got an error \"No module named 'graphviz' in Jupyter Notebook\", open anaconda prompt and type the folowing commands:\"<br>\n",
    "\"conda install -c anaconda pydot\"<br>\n",
    "\"conda install -c conda-forge python-graphviz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_for_notebook/DecisionTree_20.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_21.png\"/>\n",
    "<img src=\"images_for_notebook/DecisionTree_22.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model\n",
    "\n",
    "<img src=\"images_for_notebook/RandomForest_10.png\"/>\n",
    "<img src=\"images_for_notebook/RandomForest_11.png\"/>\n",
    "<img src=\"images_for_notebook/RandomForest_12.png\"/>\n",
    "<img src=\"images_for_notebook/RandomForest_13.png\"/>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "We'll build what's known as a random forest model. This model is constructed of several \"trees\" (there are three trees in the picture below, but we'll construct 100!), the model creates decision trees on randomly selected data samples that will individually consider each passenger's data and vote on whether the individual survived. Then, the random forest model makes a democratic decision: the outcome with the most votes wins!\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"images_for_notebook/RandomForest_1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "The code cell below looks for patterns in the different columns\\variables of the data.\n",
    "It constructs the trees in the random forest model based on patterns in the \"train\" data, before generating predictions for the passengers in \"test\" data. The code also saves these new predictions in a new CSV file.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # Importing the algorithm\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\n",
    "# define the algorithm:\n",
    "    # arg:\n",
    "        # n_estimators = number of trees\n",
    "        # max_dept = the maximum depth of the trees\n",
    "        # random_state =\n",
    "            # basically, an algorithm is repeated a number of times using random selections of features and samples. The random_state parameter allows controlling these random choices.\n",
    "            # if you call this with random_state=1 (or any other value), then each and every time, you'll get the same result.\n",
    "            \n",
    "model.fit(x_train, y_train) # running\\training the algorithm with the train data\n",
    "\n",
    "y_test_pred_RandomForest = model.predict(x_test) # making a prediction based on \"test\" data features\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'passengerid': x_test.passengerid, 'survived_what_actualy_happened':y_test, 'survived_predicted_by_model': y_test_pred_RandomForest}) # saving results to DataFrame\n",
    "output.to_csv('my_RandomForest_Prediction.csv', index=False) # saving results to csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN - K Nearest Neighbors\n",
    "\n",
    "## Show me youe neighbors and I'll tell you who you are\n",
    "\n",
    "<img src=\"images_for_notebook/Knn_10.png\"/>\n",
    "<img src=\"images_for_notebook/Knn_11.png\"/>\n",
    "<img src=\"images_for_notebook/Knn_12.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  # Importing the algorithm\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# define the algorithm:\n",
    "    # arg:\n",
    "        # n_neighbors = number of neighbors\n",
    "        \n",
    "clf.fit(x_train, y_train) # running\\training the algorithm with the train data\n",
    "\n",
    "y_test_pred_Knn = clf.predict(x_test) # making a prediction based on \"test\" data features\n",
    "\n",
    "output = pd.DataFrame({'passengerid': x_test.passengerid, 'survived_what_actualy_happened':y_test, 'survived_predicted_by_model': y_test_pred_Knn}) # saving results to DataFrame\n",
    "output.to_csv('my_Knn_Prediction.csv', index=False) # saving results to csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "\n",
    "<img src=\"images_for_notebook/Accuracy_10.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### As this is a classification problem, we can use accuracy as our evaluation metric\n",
    "### Let's import that from sklearn\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # importing \"accuracy_score\" from \"sklearn.metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Decision Tree\n",
    "test_acc = accuracy_score(y_test, y_test_pred_DecisionTree)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Random Forest\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Knn\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can easily see that the \"Decision Tree\" algo had the best result, \"Knn\" on the other hand did poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "## How do we improve our models ?\n",
    "## First, we'll need to understand what's \"overfitting\" means\n",
    "\n",
    "<img src=\"images_for_notebook/Overfitting_10.png\"/>\n",
    "<img src=\"images_for_notebook/Overfitting_11.png\"/>\n",
    "<img src=\"images_for_notebook/Overfitting_12.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting in Decision Tree\n",
    "\n",
    "<img src=\"images_for_notebook/Overfitting_DecisionTree_10.png\"/>\n",
    "<img src=\"images_for_notebook/Overfitting_DecisionTree_11.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree -- max_depth = 3 (like before)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_DecisionTree = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_DecisionTree)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree -- max_depth = 5\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_DecisionTree = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_DecisionTree)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree -- max_depth = 2\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_DecisionTree = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_DecisionTree)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree -- max_depth = 99\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=99)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_DecisionTree = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_DecisionTree)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth=3 --> look like the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 100 & max_depth = 3 (like before)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 200 & max_depth = 3\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 150 & max_depth = 3\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=150, max_depth=3, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 50 & max_depth = 3\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 10 & max_depth = 3\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looks like  \"n_estimators\" should be about a 100 (n_estimators = 100 ~ 81.5% accuracy)\n",
    "## Let's \"play\" with  \"max_depth\"\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 100 & max_depth = 5\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 100 & max_depth = 7\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 100 & max_depth = 9\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=9, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 100 & max_depth = 21\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=21, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest -- n_estimators = 100 & max_depth = 25\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=25, random_state=1)        \n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_RandomForest = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've improved our model\n",
    "## \"n_estimators=100\" & \"max_depth=25\" is a pretty good fit ~ 84%\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The impact of the number of trees\n",
    "![RandomForest](https://miro.medium.com/max/675/1*EFBVZvHEIoMdYHjvAZg8Zg.gif \"random forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting in Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_for_notebook/Overfitting_Knn_10.png\"/>\n",
    "<img src=\"images_for_notebook/Overfitting_Knn_11.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn -- n_neighbors = 3 (like before)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_Knn = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn -- n_neighbors = 7\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=7)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_Knn = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn -- n_neighbors = 9\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=9)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_Knn = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn -- n_neighbors = 33\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=33)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_Knn = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn -- n_neighbors = 100\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=100)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred_Knn = clf.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seems like the algorithm overfits a bit, also we know that KNN can highly suffer from features that are in different scales. So let's scale the x values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # import the libraries\n",
    "\n",
    "scaler = StandardScaler() # define\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train) # Fit to data, then transform it.\n",
    "x_test_scaled = scaler.transform(x_test) # Perform standardization by centering and scaling\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_test_pred_Knn_Scaled = clf.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'passengerid': x_test.passengerid, 'survived_what_actualy_happened':y_test, 'survived_predicted_by_model': y_test_pred_Knn, 'survived_predicted_by_model_scaled':y_test_pred_Knn_Scaled}) # saving results to DataFrame\n",
    "output.to_csv('my_Knn_Prediction_scaled.csv', index=False) # saving results to csv\n",
    "\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn_Scaled)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much Better !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 1,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
